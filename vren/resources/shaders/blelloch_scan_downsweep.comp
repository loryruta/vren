#version 460

#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_KHR_shader_subgroup_shuffle : require

#extension GL_EXT_debug_printf : enable

#define UINT32_MAX 0xffffffffu

#ifndef _VREN_WORKGROUP_SIZE
#	define _VREN_WORKGROUP_SIZE 1024
#endif

#define _VREN_MAX_ITEMS 1

layout(local_size_x = _VREN_WORKGROUP_SIZE, local_size_y = 1, local_size_z = 1) in;

layout(push_constant) uniform PushConstants
{
	uint swept_level; // Used only by downsweep entrypoint to find offset and stride
	uint clear_last;  // 0 if shouldn't clear last value, otherwise 1
	uint block_length;
	uint num_items;
};

layout(set = 0, binding = 0) buffer Buffer
{
	uint data[];
};

#ifdef _VREN_DOWNSWEEP_ENTRYPOINT
void main()
{
	uint block_offset = gl_WorkGroupID.y * block_length;

	uint offset = (1 << swept_level) - 1;
	uint stride = 1 << swept_level;

	for (uint i = 0; i < num_items; i++)
	{
		uint a_idx = offset + (gl_GlobalInvocationID.x * num_items + i) * stride * 2;
		uint b_idx = offset + (gl_GlobalInvocationID.x * num_items + i) * stride * 2 + stride;

		if (b_idx < block_length)
		{
			uint b = (clear_last != 0) && (b_idx == block_length - 1) ? 0 : data[block_offset + b_idx];
			data[block_offset + b_idx] = data[block_offset + a_idx] + b;
			data[block_offset + a_idx] = b;
		}
	}
}
#endif

#ifdef _VREN_WORKGROUP_DOWNSWEEP_ENTRYPOINT
shared uint s_data[1024 * _VREN_MAX_ITEMS];

void main()
{
	uint block_offset = gl_WorkGroupID.y * block_length;

	// Read global memory to shared memory
	for (uint i = 0; i < num_items; i++)
	{
		uint data_idx = gl_GlobalInvocationID.x * num_items + i;
		uint val = (clear_last != 0) && (data_idx == block_length - 1) ? 0 : data[block_offset + data_idx];
		s_data[gl_LocalInvocationID.x * num_items + i] = val;
	}
	
	barrier();

	// Workgroup-wide reduction
	uint thread_value_idx = (gl_LocalInvocationID.x + 1) * num_items - 1;

	for (int level = int(log2(_VREN_WORKGROUP_SIZE)) - 1; level >= 0; level--)
	{
		uint level_mask = (1 << (level + 1)) - 1; 
		if ((gl_LocalInvocationID.x & level_mask) == level_mask)
		{
			uint b_idx = thread_value_idx;
			uint a_idx = b_idx - (1 << level) * num_items;

			uint tmp = s_data[b_idx];
            s_data[b_idx] = s_data[a_idx] + tmp;
			s_data[a_idx] = tmp;
		}
		
		barrier();
	}

	// Invocation-wide reduction
	for (int level = int(log2(num_items)) - 1; level >= 0; level--)
	{
        for (uint i = 0; i < (num_items >> (level + 1)); i++)
        {
		    uint a_idx = (gl_LocalInvocationID.x * num_items) + (1 << level) - 1 + (i << (level + 1));
            uint b_idx = a_idx + (1 << level);

			uint tmp = s_data[b_idx];
            s_data[b_idx] = s_data[a_idx] + tmp;
			s_data[a_idx] = tmp;
        }
	}
	
	barrier();

	// Write shared memory to global memory
	for (uint i = 0; i < num_items; i++)
	{
		uint data_idx = gl_GlobalInvocationID.x * num_items + i;
		data[block_offset + data_idx] = s_data[gl_LocalInvocationID.x * num_items + i];
	}
}
#endif
